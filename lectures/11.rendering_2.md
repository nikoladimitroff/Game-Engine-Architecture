# Game Engine Architecture

## Rendering

---------------------
[Course Index](http://nikoladimitroff.github.io/Game-Engine-Architecture)

<div class="authors-section">
<table>
<tbody>
    <tr>
        <td>
            Nikola Dimitroff
        </td>
        <td>
            <a target="_blank" href="https://dimitroff.bg"><i class="fa fa-rss"></i></a>
            <a target="_blank" href="mailto:nikola@dimitroff.bg"><i class="fa fa-envelope-o"></i></a>
            <a target="_blank" href="https://github.com/nikoladimitroff"><i class="fa fa-github"></i></a>
            <a target="_blank" href="https://twitter.com/nikoladimitroff"><i class="fa fa-twitter"></i></a>
        </td>
    </tr>
    <tr>
        <td>
            Alexander Angelov
        </td>
        <td>
            <a target="_blank" href="mailto:aleksandar.angelovv@gmail.com"><i class="fa fa-envelope-o"></i></a>
            <a target="_blank" href="https://github.com/Alekssasho"><i class="fa fa-github"></i></a>
            <a target="_blank" href="https://twitter.com/Alekssasho"><i class="fa fa-twitter"></i></a>
        </td>
    </tr>
    <tr>
        <td>
            Viktor Ketipov
        </td>
        <td>
            <a target="_blank" href="mailto:viktor@kipiinteractive.com"><i class="fa fa-envelope-o"></i></a>
            <a target="_blank" href="https://github.com/k1p1"><i class="fa fa-github"></i></a>
            <a target="_blank" href="https://twitter.com/xk1p1x"><i class="fa fa-twitter"></i></a></p>
        </td>
    </tr>
</tbody>
</table>
</div>

<div class="companies-section">
<a class="ubisoft-logo" href="https://ubisoft.com" target="_blank"></a>
<br>
<a class="kipi-logo" href="http://kipiinteractive.com" target="_blank"></a>
</div>

--- NEXT SLIDE ---

# Sanity check

We are recording, aren't we?

![kitty cameraman](http://www.catster.com/wp-content/uploads/2015/06/335f4392f011a80324e09f5ace0b3f57.jpg)

--- NEXT SLIDE ---

## Review

Why isn't ray tracing appropriate for real time rendering?
* Really slow because each pixel needs tracing of many rays.
* This is starting to change in the next 5 years.

--- VERTICAL SLIDE ---

## Review

Lighting from functional point of view in real time

* Inputs
* Outputs
* Transform

## Review

Direct Lighting Inputs

 * Light Visibility    - many types
 * Materials           - BRDF formula
 * Baked data          - depends on the game
 * Lights              - many types (point, area)

--- VERTICAL SLIDE ---

 Indirect Lighting Inputs
  * Scene sampled direct lighting
  * might be offline or online
  * might be per point on the scene
  * might be recorded in space
  * Materials

--- VERTICAL SLIDE ---

Final Lighting inputs
 * Direct Lighting
 * Indirect Lighting

--- VERTICAL SLIDE ---

 Post Lighting processing
 * Tone mapping
 * Artistic postprocessing
 * Post effect antialiasing methods




* Lighting Buffer
* Typically texture 2D size of the screen, format FP16.
 * 5 bit exponent, 10 bit mantissa.
* Lights - 

--- VERTICAL SLIDE ---

## Review

What is the difference between orthographics and perspective projection?

<!-- .element class="fragment" data-fragment-index="0" --> Orthographics preserve relative sizes and parallel lines.

--- NEXT SLIDE ---

## Quick Recap

- Scene into
- Meshes into
- Triangles & Materials

- Camera & Lighting

--- NEXT SLIDE ---

## Rendering Pipeline

--- VERTICAL SLIDE ---

* Tools stage (offline). Geometry and surface properties (materials) are defined.
* Asset conditioning stage (offline). The geometry and material data are processed
by the asset conditioning pipeline (ACP) into an engine-ready
format.

--- VERTICAL SLIDE ---

* Application stage (CPU). Potentially visible mesh instances are identified
and submitted to the graphics hardware along with their materials for
rendering.

* Geometry processing stage (GPU). Vertices are transformed, lit and projected
into homogeneous clip space. Triangles are processed by the optional
geometry shader and then clipped to the frustum.

* Rasterization stage (GPU). Triangles are converted into pixels that are
shaded (coloured), passed through various tests (e.g. z-test)
and finally blended into the frame buffer.

--- VERTICAL SLIDE ---

![Pipeline](resources/10.rendering/pipeline.jpg)

--- NEXT SLIDE ---

## GPU Architecture

![GPUArch](http://www.keremcaliskan.com/wp-content/uploads/2011/01/CPU-GPU-Structures1.png)

--- VERTICAL SLIDE ---

## throughput vs latency

--- NEXT SLIDE ---

## GPU pipeline

--- VERTICAL SLIDE ---

![GPU Pipeline](https://traxnet.files.wordpress.com/2011/07/shader_full.jpeg)

--- NEXT SLIDE ---

## The hardware device

Abstracts the GPU for you

* DirectX
* OpenGL
* Console-specific
* Console on nonconsoles - DX12, Vulcan, Metal

--- VERTICAL SLIDE ---

## The shader model

The set of features supported by your GPU

* Shader model 6 is the latest and greatest

--- VERTICAL SLIDE ---

## Working with a graphics-device overview

* Initializing the device
* Using the device to create helper objects
    - Render targets
    - Textures
    - Buffers
    - Samplers, Scissors, etc.
* Binding the state
* Drawing

--- VERTICAL SLIDE ---

### Initialize the device

```cpp
// Create the swap chain, Direct3D device, and Direct3D device context.
result = D3D11CreateDeviceAndSwapChain(
   NULL, D3D_DRIVER_TYPE_HARDWARE, NULL, 0, &featureLevel, 1,
   D3D11_SDK_VERSION,
   &swapChainDesc, &m_SwapChain, &m_Devic, NULL, &m_Context);
if (FAILED(result))
{
    // Error
}
```

--- VERTICAL SLIDE ---

### Creating a resource

```cpp
D3D11_TEXTURE2D_DESC desc = { 0 };
desc.Width = 1920;
desc.Height = 1080;
desc.Format = DXGI_FORMAT_R8G8B8A8_UNORM;
desc.Usage = D3D11_USAGE_DEFAULT;
desc.BindFlags = D3D11_BIND_SHADER_RESOURCE;
D3D11_SUBRESOURCE_DATA* init = nullptr;

ID3D11Texture2D* resource;
HRESULT hr = m_Device->CreateTexture2D(&desc, init, &resource);
if (FAILED(hr))
{
    // Error
}
// Use the texture
```

--- VERTICAL SLIDE ---

### Binding state

```cpp
ID3D11ShaderResourceView* textures[MAX_TEXTURES_COUNT];
textures[0] = myTexture;
m_Context->PSSetShaderResources(0, 1, textures);

m_Context->VSSetShader(currentVS, nullptr, 0);
m_Context->PSSetShader(currentPS, nullptr, 0);
```

--- VERTICAL SLIDE ---

### Drawing

```cpp
m_Context->IASetPrimitiveTopology(D3D_PRIMITIVE_TOPOLOGY_TRIANGLELIST);
m_Context->DrawIndexed(indexCount, startIndex, baseVertexIndex);
```

--- VERTICAL SLIDE ---

### Draw loop

```cpp
SortObjectsByShaderThenByMaterial();
SetState();
for(all shaders)
    SetShaders();
    for(all materials)
        SetMaterialProperties();
        for(all meshes)
            Draw();
```

--- VERTICAL SLIDE ---

### HLSL

```cpp
struct VertexShaderInput
{
  float4 Position  : POSITION0;
  float3 Normal    : NORMAL0;
  float2 TexCoords : TEXCOORD0;
};
```

--- VERTICAL SLIDE ---

```cpp
VertexShaderOutput VertexShaderFunction(VertexShaderInput input)
{
  VertexShaderOutput output;
  float4 posWorld = mul(input.Position, World);
  output.Position = mul(posWorld, ViewProjection);
  output.TexCoords = input.TexCoords;
  output.Normal = mul(input.Normal, (float3x3)World);
  output.WorldPos = posWorld;
  return output;
}
```

--- VERTICAL SLIDE ---

```cpp
float4 PixelShaderFunction(VertexShaderOutput input) : COLOR0
{
  // Get light direction for this fragment
  float3 lightDir = normalize(input.WorldPos - LightPosition);
  float diffuseLighting = saturate(dot(input.Normal, -lightDir));
  // Using Blinn half angle modification for performance over correctness
  float3 h = normalize(normalize(CameraPos - input.WorldPos) - lightDir);
  float specLighting = pow(saturate(dot(h, input.Normal)), SpecularPower);

  return float4(
    AmbientLightColor +
    (DiffuseColor * LightDiffuseColor * diffuseLighting ) +
    (SpecularColor * LightSpecularColor * specLighting));
  }
```

--- NEXT SLIDE ---

## GPU Debugging

--- VERTICAL SLIDE ---

Every vendor has custom tools

- NVidia NSight
- AMD Perf Studio
- PIX
- Renderdoc

--- VERTICAL SLIDE ---

![renderdoc](https://www.cryengine.com/assets/images/showcase/fullsize/renderdoc1.png)

--- NEXT SLIDE ---

Functional view for the lighting process
 * What do i need to do lighting?
 * Lights, how are they represented?
 * Surfaces, how are they reprsented?
 * Where the computed results go?
 * How my input data looks like?

--- VERTICAL SLIDE ---
 Typical input data for a game

 * Choose BRDF model (GGX)
 * 







--- NEXT SLIDE ---
Graphical Processing Units

--- VERTICAL SLIDE ---
Definitions
* Latency
 *  Time to finish a fixed task
  *   33 or 16 ms frame ( 30 or 60 fps)
  *   15 ns for inserting an element into a queue
Throughput
* Tasks per unit time
  *  16 GB/s memory transfer
  *  4 Megapixels/s shading samples

--- VERTICAL SLIDE ---
Processor history

* Moore's law
 * The number of transistors can be doubled every (1.5 years) (1969)
* Performance
  * Transistor performance. 
   * Improves linearly as size scales down
  * Wires scale poorly. 
   * Delays are increased, signals are lost. Relays are installed
   * 2 km of wiring on AMD Rysen

--- VERTICAL SLIDE ---
Processor history

* TDP – Thermal design power
  * Determines cooling requirements. Measured in watts (ex. 15W, 100W, 250W)
  * Power supply and cooling match and exceed TDP
  * Power = ½ Capacitive Load * Voltage ^ 2 * Frequency
  * Capacitive Load – function of number of transistors
  * Voltage – depends on transistors
  * Frequency can be adjusted

--- VERTICAL SLIDE ---
Obstacles to increasing frequency

![Obstacles](http://www.gotw.ca/images/CPU.png)

--- VERTICAL SLIDE ---
Memory barrier - DRAM

| Year | DRAM Growth | Capacity |
| ---- | ---- | ---- |
|1990 | 60%/year | 4x/3 years |
|1996 | 60%/year | 4x/3 years |
|2003 | 40-60%/year | 4x/3-4 years |
|2007 | 40%/year | 2x/2 years |
|2011 - | 25-40%/year | 2x/2-3 years |

--- VERTICAL SLIDE ---
Capital for research

![renderdoc](http://www.yole.fr/iso_album/illus_annualcapitalexpenditure_standalonedram_yole_june2019_(430x278).jpg)

--- VERTICAL SLIDE ---
Memory barrier - speed

![Pipeline](resources/10.rendering/memory_barrier_speed.png)

* 1980: RAM latency ~ 1 cycle
* 2011: RAM latency ~ 150 - 400 + cycles

Sin(x) values in a table are faster in 1980

--- VERTICAL SLIDE ---
* CPU
  * Low latency, low throughput ( ns, < 100 GB/s )
* GPU
  * High latency, high throughput (ms, > 100 GB /s )

| | AMD Athlon II x4 | Radeon 5750 |
| ---- | ---- | ---- |
|TDP|95W| 86W|
|FLOPS| 30 GFLOPS| 1008 GFLOPS|
|Transistors| 300 M (768PH)| 1040 M|
|Bandwith GB/s| 9 ( 4 OpenCL )| 70 ( 40 OpenCL )|

--- VERTICAL SLIDE ---
CPU Components
* ALU
  * compute
* Fetch
  * instructions stream, microops
* Execution context
  * registers, where is the program
* Branch predictor
  * conditions, if, else, while, for

--- VERTICAL SLIDE ---
CPU Components

* Out of order logic
 * tries to guess where the code will go 
* Memory prefetch
 * tries to fetch memory into the cache before it is used
* Data cache (varies)
 * L1 4ns 16Kib/32Kib
 * L2 40ns 256Kib/512Kib
 * L3 100ns 16Mib

--- VERTICAL SLIDE ---
CPU
![Pipeline](resources/10.rendering/amd-cpu.jpg)

--- VERTICAL SLIDE ---
GPU - Remove complex logic, pack simpler cores
* ALU
  * compute
* Fetch
  * instructions stream, microops
* Execution context
  * registers, where is the program

--- VERTICAL SLIDE ---
 GPU - Share the fetch logic
* All cores execute the same program and the same instruction

```cpp
struct vs_output
{
  float4  position: SV_POSITION; 
  float3  normal: Normal;
  float2  uv: TexCoord; 
};

Texture2D     g_diffuse;
SamplerState  g_default_sampler;

float3        g_light_direction;

float4 main( in  vs_output input) : SV_Target
{
  float3 f_1 = diffuse.Sample(default_sampler, input.uv).xyz;
  float3 f_2 = f_1 * saturate ( dot ( light_direction, input.normal ) );
  return float4(f_2, 1.0f);
}
```
--- VERTICAL SLIDE ---
 GPU - Share the fetch logic
* All cores (70+) execute the same program and the same instruction
* Every has different data, but the code is the same

```cpp
sample r0.xyz, v2.xyxx, t0.xyzw, s0
dp3_sat r0.w, cb0[0].xyzx, v1.xyz
mul o0.xyz, r0.wwww, r0.xyzx
mov o0.w, 1(1.0000)
```
--- VERTICAL SLIDE ---
Shared execution stream
![Pipeline](resources/10.rendering/gpu-cores-shared-stream.png)

--- VERTICAL SLIDE ---
Branches
```cpp
if ( x  > 0 )
{
  x = dot(x,y);
}
else
{
  x = 2 * dot(x,y);
}
```
| T0 | T1 | T2 | T3 | T4 | T5 | T6 | T7 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| T | F | F | F | T | T | T | T |

Both branches are taken and the results are merged

--- VERTICAL SLIDE ---
GPU Stalls
* Stalls in a processor occurs, when the ALU units must wait for an external device to bring data to compute
* On CPU these units help
 * Out of order logic – scans instruction stream
 * Branch predictor – tries to predict branches, based on past branch history
 * Cache hierarchy – fast serving of memory requests if data was used before
* On GPU this was removed
* Memory latency is hundreds of cycles (500 is not uncommon)

--- VERTICAL SLIDE ---
GPU – Hiding STALLS

* Idea, saturate the gpu with work.
* Issue data request for item N, block
* Issue data request for item N + 1, block
* Issue data request for item N + 2, block

* Data comes for item N, execute
* Data comes for item N + 1, execute
* Data comes for item N + 2, execute
* After initial delay of 3, every clock we produce result

--- VERTICAL SLIDE ---
GPU – Local Data Storage on a Compute Unit

* Computation requires storage resources on the chip
* ALU registers (store intermediate results)
* Register memory comes from a register file around 128kb - 256kb
* If the shaders use small number of registers we can schedule on the unit more of them
* Less than 24 registers per shader is ideal for AMD(GCN).
* Steps are incremented in 4, 28,32, etc...

--- VERTICAL SLIDE ---
GPU Bandwitdh, theoretical

Example Radeon 5750
* Memory Controller - 73 GB/s
* 720 Processors ( 80 processors packed in 9 cores)
* 720 MHz core clock
* 720 Multiply add per clock

* Operation = C = A * B + C
 * Load A, Load B, Load C
 * Multiply 
 * Store D
 * 16 * 720 = 11520 bytes per clock
 * 720 MHz * 11520 ~ 7.54 TB/s

--- VERTICAL SLIDE ---
GPU Bandwitdh, theoretical
* Bandwidth is a critical resource
 * Must be preserved and saved with ALU computations
 * Data must be tightly packed before processing
 * Data should be reused across computing elements
 * Still GPU memory system is very effective
 * Reorders / interleaves / repacks memory

--- VERTICAL SLIDE ---
GPU Memory blocks
* L1 Cache per core (16 kb - 32kb) (RW)
* L2 Cache in MB ( RW )
* Texture Cache KB (RO).
* Textures are special packing for 2D data (morton order)
* Shared memory for a core (speed ups)

--- VERTICAL SLIDE ---
GPU Graphic Blocks
* Rasterizer
 * Produces pixels from triangles
 * Groups pixels in quads (2x2)
* Tessellator
 * Produces new triangles
* HiZ / Cull Depth
 * Helps removing invalid pixels
* Thread Scheduler
 * Schedules threads on the GPU

--- VERTICAL SLIDE ---
GPU Graphic Blocks
* Command processor
 * Parses commands from the GPU
* ROP (Raster operations)
 * Blending of pixels
* Input assembler
 * Assembles primitives for the vertex shaders
* RT Cores
 * Raytracing cores
* Tensor Cores
 * Machine learning ops

--- VERTICAL SLIDE ---
* Command generations for a game
 * CPU is responsible for generation
 * Gathers data and prepares commands draw, set texture, set blending mode, set pixel shader
 * Can be multithreaded
 * Several threads generate command buffers
 * They are chained together at the and
 * Usually double or triple buffering
 * Buffering increases parallelism
 * But increases latency also
 * 30 ms cpu generation
 * 30 ms gpu consume
 * 8-10 ms controller input
 * DirectX 11 buffers three frames by default
 * So 120 ms latency if you are at 30 fps

--- VERTICAL SLIDE ---
GPU - SUMMARY
* Pack many and simple cores on the same die
* Share instruction stream between cores
* Cover stalls with shared work

![Pipeline](resources/10.rendering/integrated-gpu.png)


--- NEXT SLIDE ---
DirectX 12 / Vulkan

--- VERTICAL SLIDE ---
DirectX 11 / OpenGL are delayed APIs By Design
* Basic problem, Frame time is unpredictable
* CPU is bottlenecked with work that may not be needed
* Pipeline states are set and parsed on draw call submission
* Triggers problems with resource usage
* Buffers my be bound on input or output operations
* Gpu Caches are flushed on every potentially every output set
* Hides memory residency

--- VERTICAL SLIDE ---
DirectX 11 / OpenGL are delayed APIs By Design
* Drivers spawn threads
* One thread per core (nvidia)
* Two core threads (intel)
* One thread for the immediate context (amd)
* They do interfere with the game threads.
* So what can we do?
* Optimize driver threads? Taxes all games, good ones and bad ones.
* If you do more work on the cpu on a laptop it remains less power for the GPU. They are tied together.

--- VERTICAL SLIDE ---
DirectX 11 / OpenGL are delayed APIs By Design
* Console developers had access to lower level GPU abstractions for years.
* Simplified apis, simplified os

--- VERTICAL SLIDE ---
DirectX 12 / Vulkan
* So what about if we level down the abstraction a bit ?
* Just little above the hardware level
* AMD did Mantle library, eventually turned out to be Vulkan  

--- VERTICAL SLIDE ---
Goals of DirectX 12

* Improve performance of CPU bound games
* Improve multicore scaling
* Improve performance on power constrained platforms
* Improve heat and battery life
* By reducing the CPU load

--- VERTICAL SLIDE ---
Main components of the API

* Memory
* Commands
* Synchronization
* Pipeline State
* Resource binding

--- VERTICAL SLIDE ---
Memory. One must manage memory by herself/himself. This is what the driver does

* Heaps
* What are resources?
* Textures, Index Buffers
* Shaders, Geometry, Buffers, ByteBuffers
* Subresources ?
* Mip 0, Mip 1 of  a texture
* Cube sides of a cube texture ?
* Texture in an array of textures.
* Reserved Resources
* Committed Resources
* Placed resources

--- VERTICAL SLIDE ---
Heaps

* Request an allocation of memory from the driver.
```cpp
d3d12device->CreateHeap( HeapDescription, Size in Bytes);
```

* Types of heaps
* VRAM of the GPU - accessed by the GPU only
* Geometry, Textures, Render Targets.
* Upload - used to transfer data across the PCI bus from the CPU to the GPU - Constants, Matrices, Streamed Geometry
* Readback - used to transfer back from the GPU - Screenshots
* Custom - UMA (consoles)

--- VERTICAL SLIDE ---
Now when one allocates the heap he must manage the memory inside. He/she must answer this questions:

* Creating resources inside, freeing resources
* How about multiple threads allocations?
* When I free something, does the gpu use it?
* What about the fragmentation of this memory?

* What about if the OS requires eviction?
* Alignment of resources
* 4 bytes for geometry
* 64KB for textures
* 4MB for MSAA render targets

--- VERTICAL SLIDE ---
When we create a heap accessible by the CPU

* Write Combine
* We must write there without holes.
* All member of the structures must be filled with data or 0.
* We bypass the cache system of the CPU. Reading is slow (hundreds of cycles)
* Suitable for write only data
* Bone Transforms is an example
* Write back
* Performs update of the page regularly
* So we may be able to write with holes or missing data.

--- VERTICAL SLIDE ---
DirectX 12 Descriptor Heaps

* We need a way to pass pointers to the GPU data around the code and dereference it on the GPU (shaders)
* On the cpu you have int32_t* or HANDLE that points to an address and you copy them around and dereference
```cpp
d3d12devicommandList->OMSetRenderTarget( gpuPointer )
```
* Descriptors come to replace the pointers for the gpu data
* They are abstraction, usually 64 or 128 bytes.

--- VERTICAL SLIDE ---
DirectX 12 Descriptor Heaps

* The driver stores data inside.
* You can create them with GPU memory
* You can copy them around to the command lists
* And you must ensure that they point to valid GPU data when used
* On the GPU

--- VERTICAL SLIDE ---
DirectX 12 Descriptor Heaps

* Descriptors are organized in a heap by types
* Shader Resource View (for reading from shaders)
* Render Target View ( for output from the shaders)
* Depth Stencil View (for the depth buffer).
* Sampler ( this is a special hardware that performs sampling )
* From the theory of signals
* Sampling means to read the values of the signals
* Geometry is a signal, Textures are signal.

--- VERTICAL SLIDE ---
DirectX 12 Examples

* <!-- .element class="fragment" data-fragment-index="0" -->Critical 
 * <!-- .element class="fragment" data-fragment-index="0" -->Must reside always
* Scaled Optional
 * Game Data - Art Supplied data
* Reused in a frame
 * Lighting Buffers, Skinning Buffers, Animation Buffers, Post Process Buffers
* Streaming resources
 * Terrain data or other big structures

--- VERTICAL SLIDE ---
Placed Resources

* Can be created in a heap.
 * Very lightweight. Can be created in a heap
  * You must manage the offset in the heap. Very useful for small data 4KB
  * Example: You allocate 32 MB for textures and manage the allocations by yourself. 
* Committed Resources
  * Backed by physical memory.
* Reserved resources
  * Allocates address space, without actual physical memory
  * Can be committed and decommitted on demand (through the device)

--- VERTICAL SLIDE ---
DIRECTX12 Work submission COMMANDS and QUEUES

* Commands, Bundles
* The CPU generates commands for the gpu in a format close the gpu
* Bundles are commands which are generated up front
* Commands are submitted in Command Lists
* Memory for Command Lists is managed by Command Allocators
* Generated commands are submitted through queues
* Queues can have different types of commands
* Direct, Bundle, Compute, Copy,  Video Decode, Video Encode
* Priority, how the OS treats the commands submitted there
* Queues can be mapped to hardware.
* Some AMD models have two queues
* Some have 64 queues
* Some have specialized queues for copy through DMA

--- VERTICAL SLIDE ---
DIRECTX12 Synchronization сFENCES

* Fences encapsulate values which increase monotonically in time.  App is responsible for increasing the fences
* Fence
* Can block a gpu queue to wait on another gpu queue
* Can block the cpu until the gpu passes a point
* Gpu
* queue->Signal(fence, 100);
* anotherQueue->Wait(fence, 100);
* Cpu
* m_fence->SetEventOnCompletion(fence, 100); WaitForSingleObject(fence, INFINITE);

--- VERTICAL SLIDE ---
DIRECTX12 Synchronization EXAMPLES

* Wait for the previous frame to finish in a double buffered scenario
* CPU Execute Commands ( frame n ), wait for the GPU to finish processing commands for frame n - 1
* Wait for the GPU to pass an execution point to transfer memory to the CPU
* Two queues graphic and compute work cooperatively to deliver better performance
* Combine memory graphics loads with compute loads

--- VERTICAL SLIDE ---
DIRECTX12 PIPELINESTATE
* Represents the whole GPU pipeline as a monolithic block
* Rasterizer, Blend State, Shaders, Depth, MSAA
* For compute just shaders
* On DX11 they are separate and the driver must check on every draw call if it was changed and rebuild
* The intended usage is that one builds either offline (consoles) or during loading time.  (Usually thousands)
* Can be cached, but the app must rebuild on os or gpu changes
* Compiling takes a lot of time 1-2 seconds

--- VERTICAL SLIDE ---
DIRECTX12 RESOURCE BINDING

* Shaders must reference resources
* Constant Buffers – constant memory for the shader
* Unordered Access Views – write for the shader
* Render targets – write for the shader
* Shader Resources Views – read for the shader
* References are descriptors which are bound to an abstraction called Root Signature
* If the contents of the descriptors do not change drivers can cache or optimize

--- VERTICAL SLIDE ---
DIRECTX12 ROOT Signature

* Similar to an API function. 
* Definition of what type of parameters the function to expect
* It may contain
* Descriptor Tables
* One or several tables with descriptors of resources
* Descriptors directly
* Several limited constants embedded directly in the command list
* example, number of a mesh
* Show example here

--- VERTICAL SLIDE ---
DIRECTX12 RESOURCE TRANSITIONS  

* Using resources for reading and writing from different Compute Units must be synchronized so we end up with deterministic data
* Resource transitions are an abstraction that covers under the hood flushes or invalidation of the gpu caches.
* Directx 11 was doing this in the driver.
* Now is offset explicitly to the app

--- VERTICAL SLIDE ---
Directx12 Resource Barсriers

* Transition Barrier
* Transition barrier indicates that a set of subresources transition between different usages
* Aliasing Barrier
* An aliasing barrier indicates a transition between usages of two different resources which have overlapping mappings into the same heap
* Unordered access view barrier
* A UAV barrier indicates that all UAV accesses, both read or write, to a particular resource must complete between any future UAV accesses, both read or write

--- VERTICAL SLIDE ---
DIRECTX12 RESOURCE TRANSITIONS  

* VERTEX_AND_CONSTANT_BUFFER 
* INDEX_BUFFER 
* RENDER_TARGET
* UNORDERED_ACCESS
* DEPTH_WRITE
* DEPTH_READ
* NON_PIXEL_SHADER_RESOURCE 
* PIXEL_SHADER_RESOURCE 
* STREAM_OUT
* INDIRECT_ARGUMENT 
* COPY_DEST 
* COPY_SOURCE 
* RESOLVE_DEST 
* RESOLVE_SOURCE 
* GENERIC_READ 
* PRESENT 
* PREDICATION 
* VIDEO_DECODE_READ,  VIDEO_DECODE_WRITE 
* VIDEO_PROCESS_READ, VIDEO_PROCESS_WRITE VIDEO_ENCODE_READ, VIDEO_ENCODE_WRITE

--- VERTICAL SLIDE ---
DIRECTX12 RESOURCE Transition EXAMPLE

* Depth Write – Depth Read
* When we bind a resource as a depth for write
* It is in compressed form in the gpu memory to accelerate rendering.
* Setting the resource for read triggers decompression, which can be 0.5 ms, depending on the resolution
* What about reading / writing multiple times in this depth resource?

--- VERTICAL SLIDE ---
Directx12 RESOURCЕ TRANSITION EXAMPLE (AMD)

* Delta Color Compression
* Form of lossless compression of the render targets on the GPU
* The key idea is to process whole blocks instead of individual pixels. Inside a block, only one value is stored with full precision, and the rest is stored as a delta – hence the name
* Clear to 0 or 1
* Do not flag render targets as shader readable unless you need them to be

--- VERTICAL SLIDE ---
DIRECTX12 Resource Transition EXAMPLE (AMD)

* Try mipmapping instead of sparsely reading images
* Write all color channels
* Organize G-Buffer Data
* If arbitrarily bit-packing fields into a G-Buffer, put highly correlated bits in the Most Significant Bits (MSBs) and noisy data in the Least Significant Bits (LSBs) of each channel. This will compress better because it responds similarly to typical data patterns.


--- VERTICAL SLIDE ---
DIRECTX12 RESOURCE TRANSITION EXAMPLE (AMD)

* Even when you've followed all the rules above, DCC may sometimes get disabled as not all parts of the GPU can read and write compressed data yet. In these cases, the barrier will result in a decompression. It is important to understand when those cases may occur:
* When simultaneously writing and reading compressed targets.
* This is not coherent between metadata and data, so corruption would occur.
* The driver has to play safe – even if there may be simultaneous access it will decompress, so make sure usage flags are properly set in explicit APIs (Direct3D® 12, Vulkan™) and surfaces unbound and/or write-masked off when not intended to be written.
* When the shader can write to the resource as an Unordered Access View (UAV)
* Flagging a texture to be writable as a UAV through the shader currently disallows compression entirely.
* Some drivers may still allow fast clears, then decompress on shader UAV write bind until the next full clear.
* Before using the copy engine.
* Generally once flagged as a copy source or target, we decompress first because we don't know where it is going.
* Raw copies can be done between surfaces of the same type and size… if the driver knows that this is going to happ

--- VERTICAL SLIDE ---
DIRECTX12 RESOURCE TRANSITION EXAMPLE (AMD)

* Unordered access view barrier
* Used very often when one have two dispatches that follow each other and must use the same resource. So we are sure they get the correct data
* Aliasing Barriers
* Used in cases when one wants to reuse the same memory for different usages. 
* Example in the beginning of the frame as geometry buffer, towards the end as a render target

--- VERTICAL SLIDE ---

* Create PSOs on worker threads asynchronously
* Start using more general PSOs (with generic shaders that compile quickly) first and generate specializations later
* Avoid runtime PSO compilations as they most likely will lead to stalls
* Minimize state changes between PSOs where possible
* Use identical sensible defaults for don't care fields wherever possible
* Use the /all_resources_bound / D3DCOMPILE_ALL_RESOURCES_BOUND compile flag if possible

--- VERTICAL SLIDE ---
* Don?t toggle between compute and graphics on the same command queue more than absolutely necessary
* Don?t toggle tessellation on/off more than absolutely necessary
* Don?t forget that PSO creation is where shaders get compiled and stalls get introduced

--- VERTICAL SLIDE ---

* Place constants and CBVs (SRVs and UAVs only if you have directly into the root signature if possible on NVIDIA Hardware
* Cache the current values of root constants, CBVs, SRVs and UAVs in CPU memory and only change the contents of the root signature when a true change is detected
* Limit the shader visibility of CBVs, SRVs and UAVs to only the necessary stages
* Minimize the number of Root Signature changes
* Gracefully handle CBV, UAV, SRV and Sampler descriptors on Tier 1 and CBV and UAV descriptors on Tier 2 hardware

--- VERTICAL SLIDE ---

* Don't group CBVs into CBV descriptor tables that have a different update frequency
* Don't bloat your root signature and descriptor tables to be able to reuse them
* Don't simultaneously set visible and deny flags for the same shader stages on root table entries
* Don't place constants SRVs and UAVs directly into the root signature unless you have a lot of draw/dispatch call that can make use of them
* Don't leave resource bindings undefined after a change of Root Signature

--- VERTICAL SLIDE ---

* Reuse allocators for similarly sized sequence of draw call
* Use 2*T + N allocators minimum
* 2* - one set of lists/allocators from last frame is still being consumed by the GPU and the second set is being built/used in the current frame
* T = #threads creating command lists – please note that allocators are not free threaded!
* N = extra pool for bundles
* Call Allocator::Reset before reusing it in another frame
* Otherwise the allocator will keep on growing until you'll run out of memory

--- VERTICAL SLIDE ---
* Don't forget that Allocator and Lists consume GPU memory
* A too large allocators may limit your GPU working set in other undesirable ways
* Don't create/destroy allocators but reuse allocators
* Save the overhead for allocator creation/destruction
* Don't reuse for differently sized sequence of draw calls
* This leads to worst case size allocator
* Don't forget to reset the corresponding allocator when resetting a set of command lists
* Not resetting an allocator means leaking memory!
* Don't free/reuse an Allocator still in use by active command lists
* сThis is illegal and may free or overwrite memory that the command list is still using


--- VERTICAL SLIDE ---
* Minimize the use of barriers and fences
* We have seen redundant barriers and associated wait for idle operations as a major performance problem for DX11 to DX12 ports
* Any barrier or fence can limit parallelism
* Make sure to always use the minimum set of resource usage flags
* Stay away from using D3D12_RESOURCE_USAGE_GENERIC_READ unless you really need every single flag that is set in this combination of flags
* Redundant flags may trigger redundant flushes and stalls and slow down your game unnecessarily
* To reiterate: We have seen redundant and/or overly conservative barrier flags and their associated wait for idle operations as a major performance problem for DX11 to DX12 ports.

--- VERTICAL SLIDE ---
* Specify the minimum set of targets in ID3D12CommandList::ResourceBarrier
* Adding false dependencies adds redundancy
* Group barriers in one call to ID3D12CommandList::ResourceBarrier
* This way the worst case can be picked instead of sequentially going through all barriers
* Use split barriers when possible
* Use the _BEGIN_ONLY/_END_ONLY flags
* This helps the driver doing a more efficient job
* Do use fences to signal events/advance across calls to ExecuteCommandLists

--- VERTICAL SLIDE ---
Key takeaway
* DirectX 12 / Vulkan
 * High performance
 * Control over scalability
* More work, better result
* Still not widely used on Mobile
* If you need simple examples, may consider DirectX 11 / OpenGL


--- VERTICAL SLIDE ---
DIRECTX12 BASICS

* So these are the basics of around 200 functions
* References:
* Gpu open
* Nvidia
* MSDN


--- NEXT SLIDE ---

# Questions?
